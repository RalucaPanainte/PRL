{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjEmtkBUpegu"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from google.colab import userdata\n",
        "from collections import Counter\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error\n",
        "\n",
        "# Assigning API KEY to initialize openai environment\n",
        "openai.api_key = \"assign your OpenAI key here\""
      ],
      "metadata": {
        "id": "dT4SmQgpr4BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the product data from the CSV file\n",
        "# Change name of file depending on what you have uploaded.\n",
        "with open(\"creative_validation.csv\", encoding='utf-8', errors='ignore') as file:\n",
        "    input_data = file.read()\n",
        "\n",
        "# Initialize the context with interaction rules and product data\n",
        "context = []\n",
        "\n",
        "# Define the chatbot's interaction rules here, including how it should greet users, provide extra information.\n",
        "\n",
        "rules = \"\"\"For this task, you'll be asked to annotate album review sentences from the Pitchfork website. Before describing the task, let's have a quick look at Pitchfork. Pitchfork is a website publishing music reviews of mainly rock, but also folk, heavy metal, electronic music and hip-hop albums.\n",
        "For each sentence group, follow these instructions :\n",
        "Carefully read the text of the review, paying close attention to details. Be careful not to use shortcuts: for example, a positive phrase does not necessarily mean creativity.\n",
        "Classify the phrase group as creative (1), uncreative (2) or indifferent (3)\n",
        "Phrases should be coded as CREATIVE when they claim that the music of the artist or band is creative. This includes references to innovation within a music genre, bridging between several music genres, risk-taking, artistic openness, and technical innovation.\n",
        "Phrases should be coded as UNCREATIVE when they evoke a lack of creativity on the part of the artist or group. This includes mentions of a blatant lack of innovation. Mentions of a lack of depth in lyrics or production. And finally, mentions of an impression of copying or déjà-vu.\n",
        "Sentence groups should be coded as INDIFFERENT when they don't fit into any of these categories.\n",
        "\"\"\"\n",
        "\n",
        "context.append({'role': 'system', 'content': f\"\"\"{rules} {input_data}\"\"\"})\n",
        "\n",
        "# Function to fetch messages from the OpenAI Chat model\n",
        "def fetch_messages(messages, model=\"gpt-4\", temperature=0):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "# Function to refresh and update the conversation context based on user input\n",
        "def refresh_conversation(chat):\n",
        "    context.append({'role': 'user', 'content': f\"{chat}\"})\n",
        "    response = fetch_messages(context, temperature=0.7)\n",
        "    context.append({'role': 'assistant', 'content': f\"{response}\"})\n",
        "    return response\n",
        "\n",
        "# Main loop to engage users in conversation\n",
        "def main():\n",
        "    results = {}\n",
        "\n",
        "    for run in range(3):\n",
        "      result = refresh_conversation(\"You were provided with a database, and your task is to classify each sentence as creative, uncreative, or indifferent. Please provide the id of the sentence along with the corresponding label.\")\n",
        "\n",
        "      #Spliting the result\n",
        "      split_result = result.split('\\n')\n",
        "\n",
        "      #Initializing an empty list to store the structured result\n",
        "      structured_result = []\n",
        "\n",
        "      #Processing stage\n",
        "      for i in split_result:\n",
        "        part = i.strip().split(', ')\n",
        "        if len(part) == 2:\n",
        "          id, label = part[0], part[1]\n",
        "          if id not in results:\n",
        "            results[id] = [id, '', '', '']\n",
        "          results[id][run + 1] = label\n",
        "\n",
        "    #Outputing the results in the CSV file\n",
        "    with open('output_all_runs.csv', 'w', newline = '') as csvfile:\n",
        "        csvwriter = csv.writer(csvfile)\n",
        "        csvwriter.writerow(['ID', 'Label 1', 'Label 2', 'Label 3'])\n",
        "\n",
        "        for row in results.values():\n",
        "          csvwriter.writerows([row])\n",
        "\n",
        "    with open(\"output_all_runs.csv\") as file:\n",
        "        input_data = file.read()\n",
        "\n",
        "      # Split data into lines\n",
        "        lines = input_data.strip().split('\\n')\n",
        "\n",
        "      # Create a dictionary to store IDs and their corresponding labels\n",
        "        id_labels = {}\n",
        "\n",
        "      # Extract IDs and labels\n",
        "        for line in lines:\n",
        "            entries = line.split(',')\n",
        "            for i in range(1, len(entries)):\n",
        "                if entries[0]:  # Check if ID exists\n",
        "                    id_ = entries[0]\n",
        "                    label = entries[i]\n",
        "                    if id_ not in id_labels:\n",
        "                        id_labels[id_] = []\n",
        "                    if label:\n",
        "                        id_labels[id_].append(label)\n",
        "\n",
        "    with open('output.csv', 'w', newline='') as csvfile:\n",
        "        csvwriter = csv.writer(csvfile)\n",
        "        csvwriter.writerow(['ID', 'Label'])\n",
        "        #Finding the majority label\n",
        "        for id_, labels in id_labels.items():\n",
        "            if labels:  # Check if there are labels for this ID\n",
        "                majority_label = Counter(labels).most_common(1)[0][0]\n",
        "                csvwriter.writerow([id_, majority_label])\n",
        "\n",
        "    # Load ground truth labels\n",
        "    with open(\"creative_validation_ground_truth.csv\") as file:\n",
        "        ground_truth_data = file.readlines()\n",
        "\n",
        "    # Load predicted labels\n",
        "    with open(\"output.csv\") as file:\n",
        "        predicted_data = file.readlines()\n",
        "\n",
        "    # Initialize lists to store ground truth and predicted labels\n",
        "    ground_truth_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    # Process ground truth and predicted data\n",
        "    for ground_truth_line, predicted_line in zip(ground_truth_data, predicted_data):\n",
        "        _, ground_truth_label = ground_truth_line.strip().split(',')\n",
        "        _, predicted_label = predicted_line.strip().split(',')\n",
        "        ground_truth_labels.append(ground_truth_label)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    #Removing the first element since its the header \"Label\"\n",
        "    ground_truth_labels.pop(0)\n",
        "    predicted_labels.pop(0)\n",
        "    ground_truth_labels.pop(0)\n",
        "    predicted_labels.pop(0)\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    accuracy = accuracy_score(ground_truth_labels, predicted_labels)\n",
        "    precision = precision_score(ground_truth_labels, predicted_labels, average='macro')\n",
        "    recall = recall_score(ground_truth_labels, predicted_labels, average='macro')\n",
        "    f1 = f1_score(ground_truth_labels, predicted_labels, average='macro')\n",
        "    cross_tab = pd.crosstab(ground_truth_labels, predicted_labels)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1-score:\", f1)\n",
        "    print(cross_tab)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "N1AM6pvrsA_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ajnQMLlhw7em"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}